# **Curso de Big Data com Hadoop - Dia 10/03 - Manhã**
## Introdução a ciência de dados
  O Data Science é a ciência que explora a análise de dados e com isso poder entender e extrair informações e padrões destes dados. Com a Big Data, a ciência de dados está conseguindo um valor grande para o processamento, descoberta de padrões e informações por estes dados por várias fontes e com várias velocidades.
## Principais Ferramnentas de um Cientista de Dados
 * Programação - Conhecimento de Linguagens. (Python, R, Julia, Scala e até Java)
 * Pensamento Lógico - Requer lógica para entender padrões e para programação também
 * Habilidade com Números - Os algoritmos são baseados em conceitos matemáticos e estatísticos
 * Conhecimento em Bancos de Dados -  Para requerer as informações para a análise
 ## 10(+1) Habilidades do Cientista de Dados
  0. *TER INGLÊS FLUENTE*
  1. Comunicação
  2. Gestão de Dados Estruturados
  3. Matemática
  4. Gestão de Projetos
  5. Data Mining e Visualização
  6. Design de Experimentos
  7. Design e Desenvolvimento de Produtos
  8. Gestão de Dados
  9. Modelagem estatística (R!!!)
  10. Desenvolvimento de Negócios
  * Obs: Não faça sobre-trabalho!!
 ## Carreira Profissional e Certificações
 * O Certified Analytics Professional (CAP) oferecido pela Informs. Forte no EUA! Deve ser bom em tudo (Matemática, Estatística, Análise, Programação e BD).
 * Microsoft com MCSE Data Management and Analytics e MCSA Data Science. Requer conhecimento com Azure, Linguagem Azure, Linguagem R, Serviços Cognitivos e Chatbots. Recomendado para iniciantes para fazer o MCSA.
 * IBM Watson com duas cerificações com Big Data e uma de arquitetura de soluções. Arquiteto de Big Data, Engenheiro de Big Data e Developer de Aplicações - Watson. Recomendado tirar Arquiteto ou Developer Watson.
 * Cloudera oferece 4 cursos! CCP Data Eng, CCA Spark e Hadoop, CCA Data Analyt. e CCA Adm. (Muito bem visto!)
 * Hortonworks fornece alguns frameworks para Big Data e é uma das principais fornecedoras para ecosistemas Hadoop.
 * Dell tem a EMC Data Science Associate.
 * MongoDB com certificação MongoDB DBA e Certified Developer Associate.
 * SAS oferece um software para análise de dados. SAS Certified Big Data Professional e Adavanced Analytics Professional.
 * AWS da Amazon Web Services de Certified Solutions Arquitect - Associate.
## O que levou a criação do Hadoop
 * Precisamos entender primeiro o que é Big Data.
 * Big Data é um conjunto de dados gigantesco.
 * O FB tenha um conjunto de dados relacionais com era 15TB em 2007 para 700TB em 2010(!!). Mas atualmente (2018-03-18), é mais problemático com 300PB(!!!!!) por dia!
## Entendendo o que é Big Data
 ### Os cinco 5v's
  1. Veracidade - A fonte de dados é consistente?
  2. Velocidade - Como encontrar o que preciso em tempo real?
  3. Volume - Como armazenar esta quantidade imensa de informação?
  4. Variedade - Como encontrar o que preciso em meio a imensa variedade?
  5. Valor - Entregou o valor que precisava?
## Qual a importância da Big Data?
  * A importância de conseguir padrões e na quantidade de dados entender como melhorar a empresa e serviços.
  * Com a análise de dados, podemos:
    1. Redução de Tempo
    2. Redução de Custos
    3. Prover soluções mais inteligentes
    4. Prover soluções para aumentar a qualidade
 ## O que é Hadoop?
  * Projeto livre da Apache Fundation
  * Voltada para cluster e processamento de grandes dados
  * Composto por:
    * HDFS: Hadoop Distributed File System
    * Yarn
    * Map Reducer
  * Ecosistema Hadoop
 ## Introdução a Machine Learning
  * O M.L. leva algumas das ideias fundamentais de IA e as utilizam na resolução em problemas do mundo real com redes neutrais.
  * Construções lógicas que com uma série de perguntas conseguem uma série de outputs.
  * Por definição, M.L. é uma automatização de modelos analíticos.
  * Ou seja, conseguir desenvolver algoritmos que aprendam sozinhos para ligar pontos e informações que passam por não percebidos.
  * Tipos de algoritmos:
    1. Aprendizagem supervisionada: Consiste em um algortimos que já possuem modelos preestabelecidos.
    2. Aprendizagem não supervisionada: Não é apresentado ao algoritmo nenhum modelo predeterminado.
   * Tipos de tarefas:
    * Classificação: O algoritmo possui o objetivo de classificar dados. Ou seja, classificar um tipo de dado com base em rótulos.
    * Regressão: Possui a tarefa de prever valores e comportamentos a partir da análise de dados.
    * Agrupamentos: O algoritmo possui a tarefa de separar os dados tem grupos, seguimentados por características similares.
## Aplicações de Machine Learning
  * Detecção de Fraudes
  * Liberação de crédito
  * Resultados de pesquisa na Web
  * Anúncios em tempo real em páginas da web e disposistivos móveis
  * Análise de sentimento baseada em texto
  * Pontuação de crédito
  * Previsão de falhas em equipamento
  * Novos modelos de precificação
  * Detecção de invasão da rede
  * Reconhecimento de padrões e imagem
  * Fitragem de spam nos e-mails
## Cases de sucesso
  * Amazon - "Outros compram também"
  * Google Now e Alexa - "Aprende" a rotina da diária da pessoa.
  * Ministério da Justiça - Dar mais agilidade para os processos por OCR. Ajudar na tomada de decisão, pode fornecer pareceres para o processo. Utiliza o IBM Watson. Pode fornecer petabytes por segundo.
  * UPS - Economia de 5 milhões de litros de gasonlina, manutenção e aumento nas entregas. Com o cruzamento de diversos dados (Rotas,velocidade,tempo gasto/entrega e RPM)
  * NetFlix - Algoritmos especialistas. Personalização de conteúdo, hábitos, distribuír o conteúdo e analisar os dispositivos.
## Introdução a Python, R e Pig
  1. Python
     * Código aberto
     * IDE's
     * Operadores
     
# Tarefa de Casa
  1. Estudar Tableau
  2. Estudar PowerBI, PW(Spoon)
